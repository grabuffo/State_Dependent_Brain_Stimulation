{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1VeolR4xuSSancsqd3KYTuefPh4IGB700?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "a5MjF9v6Vr4Q",
    "outputId": "9ce233d3-85c6-4c36-e409-4cb1d1cac385",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "import pickle\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "axPYZc9FQT7z",
    "outputId": "8553faf2-55a4-4e8f-ca84-eceb5b2bd011",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# URL to the stim_info.csv file on GitHub repository\n",
    "path = '../data/'\n",
    "\n",
    "# Load stimulation site information directly from the GitHub raw URL\n",
    "stim_info = pd.read_csv(path+'stim_info.csv')\n",
    "sub2use = 'sub-01'\n",
    "run = 'run-01'\n",
    "\n",
    "# Filter by subject and run, extract the stimulation coordinates, and compute the Euclidean distance between the stimulation site and each brain region centroid.\n",
    "filtered_df = stim_info[(stim_info['Subject'] == sub2use) & (stim_info['Run'] == run)]\n",
    "sito_stim = np.array([filtered_df['x_MNI'].values[0], filtered_df['y_MNI'].values[0], filtered_df['z_MNI'].values[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5enF2qZS5GlG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../data/SEEG/sub1/sub-01_run-01_epoched.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     700.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-5f25a8a9fe09>:9: RuntimeWarning: This filename (../data/SEEG/sub1/sub-01_run-01_epoched.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  eeg = mne.read_epochs(path + 'SEEG/sub1/' + sub2use + '_' + run + '_epoched.fif').filter(None, 40., h_trans_bandwidth='auto', filter_length='auto',phase='zero', verbose=False).apply_baseline(baseline)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "percentages = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "ini_pre, fini_pre = 25, 250\n",
    "ini_post, fini_post = 310, 900\n",
    "\n",
    "stim_info = pd.read_csv(path + 'stim_info.csv')\n",
    "filtered_df = stim_info[(stim_info['Subject'] == sub2use) & (stim_info['Run'] == run)]\n",
    "\n",
    "baseline = (-0.3, -0.05)\n",
    "eeg = mne.read_epochs(path + 'SEEG/sub1/' + sub2use + '_' + run + '_epoched.fif').filter(None, 40., h_trans_bandwidth='auto', filter_length='auto',phase='zero', verbose=False).apply_baseline(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat_wake=np.swapaxes(np.swapaxes(eeg.get_data(),0,2),0,1)\n",
    "dat_wake=dat_wake[:,:-1,:]\n",
    "\n",
    "idx2use = eeg.ch_names.index(np.array(filtered_df['Stimulation channels'])[0])\n",
    "\n",
    "stim_coords = eeg.info['dig'][idx2use + 3]['r']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage=percentages[-1]\n",
    "\n",
    "distances = np.zeros((len(eeg.ch_names)))\n",
    "\n",
    "\n",
    "for xx in range(len(eeg.ch_names)):\n",
    "  ch2use = eeg.info['dig'][xx + 3]['r']*1000\n",
    "  distances[xx] = np.sqrt(np.sum((stim_coords-ch2use)**2, axis=0))\n",
    "\n",
    "ch_index2use = np.argsort(distances)[:int(distances.shape[0] * percentage / 100)]\n",
    "R = int(distances[ch_index2use[-1]]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hGygSRwodvbj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetricsOfInterest loop through trials...\n",
      "compute features for trial 0\n",
      "compute features for trial 1\n",
      "compute features for trial 2\n",
      "compute features for trial 3\n",
      "compute features for trial 4\n",
      "compute features for trial 5\n",
      "compute features for trial 6\n",
      "compute features for trial 7\n",
      "compute features for trial 8\n",
      "compute features for trial 9\n",
      "compute features for trial 10\n",
      "compute features for trial 11\n",
      "compute features for trial 12\n",
      "compute features for trial 13\n",
      "compute features for trial 14\n",
      "compute features for trial 15\n",
      "compute features for trial 16\n",
      "compute features for trial 17\n",
      "compute features for trial 18\n",
      "compute features for trial 19\n",
      "compute features for trial 20\n",
      "compute features for trial 21\n",
      "compute features for trial 22\n",
      "compute features for trial 23\n",
      "compute features for trial 24\n",
      "compute features for trial 25\n",
      "compute features for trial 26\n",
      "compute features for trial 27\n",
      "compute features for trial 28\n",
      "compute features for trial 29\n",
      "compute features for trial 30\n",
      "compute features for trial 31\n",
      "compute features for trial 32\n",
      "compute features for trial 33\n",
      "compute features for trial 34\n",
      "compute features for trial 35\n",
      "compute features for trial 36\n",
      "compute features for trial 37\n",
      "compute features for trial 38\n",
      "compute features for trial 39\n",
      "MetricsOfInterest loop through trials...\n",
      "compute features for trial 0\n",
      "compute features for trial 1\n",
      "compute features for trial 2\n",
      "compute features for trial 3\n",
      "compute features for trial 4\n",
      "compute features for trial 5\n",
      "compute features for trial 6\n",
      "compute features for trial 7\n",
      "compute features for trial 8\n",
      "compute features for trial 9\n",
      "compute features for trial 10\n",
      "compute features for trial 11\n",
      "compute features for trial 12\n",
      "compute features for trial 13\n",
      "compute features for trial 14\n",
      "compute features for trial 15\n",
      "compute features for trial 16\n",
      "compute features for trial 17\n",
      "compute features for trial 18\n",
      "compute features for trial 19\n",
      "compute features for trial 20\n",
      "compute features for trial 21\n",
      "compute features for trial 22\n",
      "compute features for trial 23\n",
      "compute features for trial 24\n",
      "compute features for trial 25\n",
      "compute features for trial 26\n",
      "compute features for trial 27\n",
      "compute features for trial 28\n",
      "compute features for trial 29\n",
      "compute features for trial 30\n",
      "compute features for trial 31\n",
      "compute features for trial 32\n",
      "compute features for trial 33\n",
      "compute features for trial 34\n",
      "compute features for trial 35\n",
      "compute features for trial 36\n",
      "compute features for trial 37\n",
      "compute features for trial 38\n",
      "compute features for trial 39\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/SEEG/sub1/sub-01/sub-01_run-01_100_metrics.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-af0b45905341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'SEEG/sub1/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub2use\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub2use\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_metrics.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m    \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/SEEG/sub1/sub-01/sub-01_run-01_100_metrics.pkl'"
     ]
    }
   ],
   "source": [
    "metrics_pre, metrics_post, Corr, Piva = fun.analyze_pre_VS_post(dat_wake, distances=distances, R=R, ini_pre=ini_pre, fini_pre=fini_pre, ini_post=ini_post, fini_post=fini_post)\n",
    "\n",
    "data_save = {\n",
    "   'metrics_pre': metrics_pre,\n",
    "   'metrics_post': metrics_post,\n",
    "   'Corr': Corr,\n",
    "   'Piva': Piva\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'SEEG/sub1/' + sub2use  + '_' + run + '_Radius-' + str(percentage) + '_metrics.pkl', 'wb') as file:\n",
    "   pickle.dump(data_save, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4NKJrhH3Hp+l+jZ7lIz4X",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
