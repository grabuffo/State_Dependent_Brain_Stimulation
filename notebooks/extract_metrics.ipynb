{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marangiol/BrainStimulation/blob/main/extract_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "a5MjF9v6Vr4Q",
    "outputId": "9ce233d3-85c6-4c36-e409-4cb1d1cac385",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "import pickle\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "axPYZc9FQT7z",
    "outputId": "8553faf2-55a4-4e8f-ca84-eceb5b2bd011",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# URL to the stim_info.csv file on GitHub repository\n",
    "path = '../data/'\n",
    "\n",
    "# Load stimulation site information directly from the GitHub raw URL\n",
    "stim_info = pd.read_csv(path+'stim_info.csv')\n",
    "sub2use = 'sub-03'\n",
    "run = 'run-08'\n",
    "\n",
    "# Filter by subject and run, extract the stimulation coordinates, and compute the Euclidean distance between the stimulation site and each brain region centroid.\n",
    "filtered_df = stim_info[(stim_info['Subject'] == sub2use) & (stim_info['Run'] == run)]\n",
    "sito_stim = np.array([filtered_df['x_MNI'].values[0], filtered_df['y_MNI'].values[0], filtered_df['z_MNI'].values[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5enF2qZS5GlG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../data/hd-EEG/sub1/sub-03_run-08_epoched.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     700.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-63d07053dc61>:9: RuntimeWarning: This filename (../data/hd-EEG/sub1/sub-03_run-08_epoched.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  eeg = mne.read_epochs(path + 'hd-EEG/sub1/' + sub2use + '_' + run + '_epoched.fif').filter(None, 40., h_trans_bandwidth='auto', filter_length='auto',phase='zero', verbose=False).apply_baseline(baseline)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "29 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "percentage = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "ini_pre, fini_pre = 25, 250\n",
    "ini_post, fini_post = 310, 900\n",
    "\n",
    "stim_info = pd.read_csv(path + 'stim_info.csv')\n",
    "filtered_df = stim_info[(stim_info['Subject'] == sub2use) & (stim_info['Run'] == run)]\n",
    "\n",
    "baseline = (-0.3, -0.05)\n",
    "eeg = mne.read_epochs(path + 'hd-EEG/sub1/' + sub2use + '_' + run + '_epoched.fif').filter(None, 40., h_trans_bandwidth='auto', filter_length='auto',phase='zero', verbose=False).apply_baseline(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat_wake=np.swapaxes(np.swapaxes(eeg.get_data(),0,2),0,1)\n",
    "dat_wake=dat_wake[:,:-1,:]\n",
    "\n",
    "idx2use = eeg.ch_names.index(np.array(filtered_df['Stimulation channels'])[0])\n",
    "\n",
    "stim_coords = eeg.info['dig'][idx2use + 3]['r']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.zeros((len(eeg.ch_names)))\n",
    "\n",
    "\n",
    "for xx in range(len(eeg.ch_names)):\n",
    "  ch2use = eeg.info['dig'][xx + 3]['r']*1000\n",
    "  distances[xx] = np.sqrt(np.sum((stim_coords-ch2use)**2, axis=0))\n",
    "\n",
    "ch_index2use = np.argsort(distances)[:int(distances.shape[0] * percentage / 100)]\n",
    "R = int(distances[ch_index2use[-1]]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGygSRwodvbj"
   },
   "outputs": [],
   "source": [
    "metrics_pre, metrics_post, Corr, Piva = fun.analyze_pre_VS_post(dat_wake, distances=distances, R=R, ini_pre=ini_pre, fini_pre=fini_pre, ini_post=ini_post, fini_post=fini_post)\n",
    "\n",
    "data_save = {\n",
    "   'metrics_pre': metrics_pre,\n",
    "   'metrics_post': metrics_post,\n",
    "   'Corr': Corr,\n",
    "   'Piva': Piva\n",
    "}\n",
    "\n",
    "with open(path + 'hd-EEG/sub1/' + sub2use + '/' + sub2use  + '_' + run + '_' + str(percentage) + '_metrics.pkl', 'wb') as file:\n",
    "   pickle.dump(data_save, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4NKJrhH3Hp+l+jZ7lIz4X",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
